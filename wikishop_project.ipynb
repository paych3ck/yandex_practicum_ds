{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "1. Загрузка и подготовка данных.\n",
    "2. Обучение разных моделей. \n",
    "3. Выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка баланса классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явный дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned = re.sub(r'[^А-Яа-яA-Za-z]', ' ', text).lower()\n",
    "    return cleaned\n",
    "\n",
    "#w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "#lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "load_model = spacy.load('en_core_web_sm', disable = ['parser','ner'])\n",
    "\n",
    "def lemmatize_and_clean(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    doc = load_model(cleaned_text)\n",
    "    #return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(cleaned_text)])\n",
    "    return ' '.join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24630eec29249009055333d50256f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww   he match this background colour I m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man   I m really not try to edit war   it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more I can t make any real suggestion on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you   sir   be my hero   any chance you rememb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  d aww   he match this background colour I m se...  \n",
       "2  hey man   I m really not try to edit war   it ...  \n",
       "3     more I can t make any real suggestion on im...  \n",
       "4  you   sir   be my hero   any chance you rememb...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "data['lemmatized_text'] = data['text'].progress_map(lemmatize_and_clean)\n",
    "features_train, features_test, target_train, target_test = train_test_split(data['lemmatized_text'], data['toxic'], test_size=0.1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование текста в векторы признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(features_train)\n",
    "X_test_vectorized = vectorizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7726993006684721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=10, class_weight='balanced')\n",
    "\n",
    "scores_list = cross_val_score(estimator=model, \n",
    "                              X=X_train_vectorized, \n",
    "                              y=target_train, \n",
    "                              cv=5,  \n",
    "                              scoring=\"f1\")\n",
    "\n",
    "val_score = scores_list.mean()\n",
    "print(\"F1 score:\", val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MultinomialNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6227892632303382\n",
      "Лучшие параметры: {'alpha': 0.1, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(nb_model, param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train_vectorized, target_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "#y_pred = best_model.predict(X_test_vectorized)\n",
    "#f1 = f1_score(target_test, y_pred)\n",
    "print(\"F1 Score:\", best_score)\n",
    "print(\"Лучшие параметры:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве лучшей модели выбираем LogisticRegression с гиперпараметром *C* равным 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7766657134686874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_vectorized, target_train)\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "f1 = f1_score(target_test, y_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы был проанализирован датасет. Был выявлен дисбаланс классов, который в дальнейшем был учтен при инициализациии моделей. Удовлетворительный результат F1-score показала модель **LogisticRegression** - 0,7766657134686874."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 8914,
    "start_time": "2023-07-04T20:58:01.953Z"
   },
   {
    "duration": 240,
    "start_time": "2023-07-04T20:58:10.869Z"
   },
   {
    "duration": 3644,
    "start_time": "2023-07-04T23:28:08.046Z"
   },
   {
    "duration": 2277,
    "start_time": "2023-07-04T23:28:11.692Z"
   },
   {
    "duration": 32,
    "start_time": "2023-07-04T23:28:13.971Z"
   },
   {
    "duration": 27,
    "start_time": "2023-07-04T23:28:14.005Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-04T23:28:14.034Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-04T23:28:14.043Z"
   },
   {
    "duration": 336,
    "start_time": "2023-07-04T23:28:14.054Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:28:14.392Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:28:14.393Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:28:14.395Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:28:14.396Z"
   },
   {
    "duration": 3591,
    "start_time": "2023-07-04T23:28:47.503Z"
   },
   {
    "duration": 796,
    "start_time": "2023-07-04T23:28:51.096Z"
   },
   {
    "duration": 40,
    "start_time": "2023-07-04T23:28:51.893Z"
   },
   {
    "duration": 26,
    "start_time": "2023-07-04T23:28:51.934Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-04T23:28:51.963Z"
   },
   {
    "duration": 36,
    "start_time": "2023-07-04T23:28:51.983Z"
   },
   {
    "duration": 652,
    "start_time": "2023-07-04T23:28:52.021Z"
   },
   {
    "duration": 71607,
    "start_time": "2023-07-04T23:28:52.675Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:30:04.284Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:30:04.285Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:30:04.286Z"
   },
   {
    "duration": 3618,
    "start_time": "2023-07-04T23:30:20.627Z"
   },
   {
    "duration": 846,
    "start_time": "2023-07-04T23:30:24.247Z"
   },
   {
    "duration": 39,
    "start_time": "2023-07-04T23:30:25.094Z"
   },
   {
    "duration": 29,
    "start_time": "2023-07-04T23:30:25.135Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-04T23:30:25.166Z"
   },
   {
    "duration": 12,
    "start_time": "2023-07-04T23:30:25.177Z"
   },
   {
    "duration": 629,
    "start_time": "2023-07-04T23:30:25.190Z"
   },
   {
    "duration": 46968,
    "start_time": "2023-07-04T23:30:25.821Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:31:12.791Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:31:12.792Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T23:31:12.794Z"
   },
   {
    "duration": 3740,
    "start_time": "2023-07-04T23:31:30.370Z"
   },
   {
    "duration": 811,
    "start_time": "2023-07-04T23:31:34.112Z"
   },
   {
    "duration": 37,
    "start_time": "2023-07-04T23:31:34.924Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-04T23:31:34.963Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-04T23:31:34.990Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-04T23:31:35.009Z"
   },
   {
    "duration": 613,
    "start_time": "2023-07-04T23:31:35.032Z"
   },
   {
    "duration": 1040514,
    "start_time": "2023-07-04T23:31:35.647Z"
   },
   {
    "duration": 7359,
    "start_time": "2023-07-04T23:48:56.162Z"
   },
   {
    "duration": 51813,
    "start_time": "2023-07-04T23:49:03.522Z"
   },
   {
    "duration": 2628,
    "start_time": "2023-07-04T23:49:55.337Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-04T23:51:01.595Z"
   },
   {
    "duration": 307,
    "start_time": "2023-07-04T23:55:30.332Z"
   },
   {
    "duration": 1010,
    "start_time": "2023-07-04T23:55:42.023Z"
   },
   {
    "duration": 1055,
    "start_time": "2023-07-04T23:56:28.970Z"
   },
   {
    "duration": 58,
    "start_time": "2023-07-04T23:56:51.459Z"
   },
   {
    "duration": 565,
    "start_time": "2023-07-04T23:56:55.899Z"
   },
   {
    "duration": 765933,
    "start_time": "2023-07-04T23:57:25.551Z"
   },
   {
    "duration": 520542,
    "start_time": "2023-07-05T00:10:23.925Z"
   },
   {
    "duration": 13724,
    "start_time": "2023-07-05T00:19:14.644Z"
   },
   {
    "duration": 53293,
    "start_time": "2023-07-05T00:19:57.039Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-05T00:22:57.996Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-05T00:23:03.924Z"
   },
   {
    "duration": 249045,
    "start_time": "2023-07-05T00:23:09.988Z"
   },
   {
    "duration": 2359,
    "start_time": "2023-07-05T00:30:08.095Z"
   },
   {
    "duration": 2456,
    "start_time": "2023-07-05T00:30:17.251Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-05T00:30:58.417Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-05T00:31:03.761Z"
   },
   {
    "duration": 2414,
    "start_time": "2023-07-05T00:31:44.761Z"
   },
   {
    "duration": 52483,
    "start_time": "2023-07-05T00:32:10.362Z"
   },
   {
    "duration": 1068,
    "start_time": "2023-07-05T12:54:43.841Z"
   },
   {
    "duration": 18905,
    "start_time": "2023-07-05T12:54:52.066Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-05T12:55:15.415Z"
   },
   {
    "duration": 268,
    "start_time": "2023-07-05T12:55:21.867Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-05T12:55:28.212Z"
   },
   {
    "duration": 3363,
    "start_time": "2023-07-05T13:00:39.107Z"
   },
   {
    "duration": 2297,
    "start_time": "2023-07-05T13:00:42.472Z"
   },
   {
    "duration": 29,
    "start_time": "2023-07-05T13:00:44.770Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-05T13:00:44.800Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-05T13:00:44.827Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-05T13:00:44.844Z"
   },
   {
    "duration": 798,
    "start_time": "2023-07-05T13:00:44.857Z"
   },
   {
    "duration": 1057007,
    "start_time": "2023-07-05T13:00:45.656Z"
   },
   {
    "duration": 7646,
    "start_time": "2023-07-05T13:18:22.683Z"
   },
   {
    "duration": 263751,
    "start_time": "2023-07-05T13:18:30.331Z"
   },
   {
    "duration": 2658,
    "start_time": "2023-07-05T13:22:54.084Z"
   },
   {
    "duration": 55833,
    "start_time": "2023-07-05T13:22:56.744Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
